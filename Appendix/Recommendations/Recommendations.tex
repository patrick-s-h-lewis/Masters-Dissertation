\label{chapt:RECOMMENDATIONS}
As alluded to in the text, there are several recommendations for further work. The code and data will be improved and amended over time, and is freely available under MIT licence on request \footnote{A digital copy is included with this dissertation.}. If attempting to carry out further work on this project, it is recommended to contact the author for in-depth explanations. This list is by no means exhaustive, and it is the author's belief that literature semantic analysis should be considered an important analytical chemical tool.
\subsection{Greater Dimensionality and Training Improvements}
The principles behind the methods discussed in the project have been shown to be sound. Models should now be improved. Computing resources should be obtained to train higher dimensional vectors \footnote{ The author recommends 400 dimensional vectors}. The models should also be trained for longer ($> 24$) epochs on more data ($> 460000$ documents). These steps will lead to more expressive models.
\subsection{Greater use of word vectors}
This project focussed mainly on document vectors. However, word vectors may be very useful. A method for testing the quality of improved models should be developed. This could take the form of expected relationships to test the model: e.g. Fluorine is to Fluoride as Chlorine is to ... . Many hundreds of these relationships should be systematically built up to test model intuition.\footnote{This would probably require much larger, more descriptive training sets, e.g. textbook transcipts etc.} This follows the methodologies set out in the literature \cite{word2vec1} \cite{word2vec2}. Furthermore, is it possible to predict chemical properties using semantic relationships found in the literature? Vec(Compound A) + Vec(Compound B) + Vec(Lab Technique) may give vec(Product C). If so, it may be possible to find unexpected reactions. This could be coupled with the RInChI database to form a new type of data-driven cheminformatics.
\subsection{Time resolution in clustering}
Methods have been described for clustering documents. The cluster centres represent the content of the cluster effectively. By finding early papers in the cluster, is it possible to identify influential papers or authors?
By clustering on documents from particular years, is it possible to identify a path for the evolving cluster centre vector? If so, it should be possible to extrapolate to \emph{predict} near future research directions.
\subsection{Open Source Chemistry Vectors}
With the increase in open source papers, it should be possible to build up a vast dataset of chemical language for training, using the bodies of articles published on open source platforms, and even to use supplied supporting information. 
\subsection{Structure stemming}
Chemical names could be smartly preprocessed to classes of chemicals, for example by identifying a compound from its name and mapping to InChI key, then to a chemical class. This would allow better association of chemical fragments in training.
\subsection{Multiply labelled Documents}
In Training Doc2Vec, by specifying document with more than just their unique identifiers allows more vectors to be associated. By identifying and labelling all documents with a particular concept, e.g. `palladium-catalysed', and then training Doc2Vec, one defines an 'palladium-catalysed' vector, specifically trained for the concept. These concept vectors would be robust and information-rich\footnote{e.g. which documents are close to the indium-catalysed vector but do not contain the word indium...}