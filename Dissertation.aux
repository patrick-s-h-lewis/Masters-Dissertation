\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrtnat}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{2}{chapter*.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{3}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Modern Scientific Publishing}{3}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Motivation}{3}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Aims}{3}{section.1.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Data Acquisition}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt:DATA_ACQUISITION}{{2}{5}{Data Acquisition}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Background}{5}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}HTML and Xpath}{5}{subsection.2.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Tree representation of HTML code. The html code here displays a table with 3 rows. The page has two peices of metadata associated with it, stored in the `head'.}}{5}{figure.2.1}}
\newlabel{fig:HTMLTREE}{{2.1}{5}{Tree representation of HTML code. The html code here displays a table with 3 rows. The page has two peices of metadata associated with it, stored in the `head'}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Automatic Xpath Generation}{6}{section.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Collection Strategy}{6}{section.2.3}}
\citation{CROSSREF-FORMATION}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Document Object Identifiers}{7}{subsection.2.3.1}}
\newlabel{sec:DOI}{{2.3.1}{7}{Document Object Identifiers}{subsection.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Doi structure. The structure consists of a numeric prefix (X and Y must be integers) and alphanumeric suffix (Z can be any Unicode encoded character) }}{7}{figure.2.2}}
\newlabel{fig:DOI}{{2.2}{7}{Doi structure. The structure consists of a numeric prefix (X and Y must be integers) and alphanumeric suffix (Z can be any Unicode encoded character)}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Perl Syntax Code that can identify the vast majority of DOIs within free text) }}{8}{figure.2.3}}
\newlabel{fig:REGEX}{{2.3}{8}{Perl Syntax Code that can identify the vast majority of DOIs within free text)}{figure.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Scraping Program}{8}{subsection.2.3.2}}
\newlabel{sec:SCRAPING_PROGRAM}{{2.3.2}{8}{Scraping Program}{subsection.2.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The data flow of the scraping program. An inputted list of websites to scrape are visited and dois are extracted in the process described in \ref  {sec:DOI}. The Crossref API service is then used to verify the extracted dois, and collects available meta-data. The program then accesses publisher webpages and collects the abstracts. The program also produces explanation of capture failures and some general statistics}}{9}{figure.2.4}}
\newlabel{fig:Cherry}{{2.4}{9}{The data flow of the scraping program. An inputted list of websites to scrape are visited and dois are extracted in the process described in \ref {sec:DOI}. The Crossref API service is then used to verify the extracted dois, and collects available meta-data. The program then accesses publisher webpages and collects the abstracts. The program also produces explanation of capture failures and some general statistics}{figure.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Collection Results}{10}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}UK University Department scraping}{10}{subsection.2.4.1}}
\newlabel{sec:UKSCRAPE}{{2.4.1}{10}{UK University Department scraping}{subsection.2.4.1}{}}
\newlabel{tab:UKSCRAPERES}{{2.4.1}{10}{UK University Department scraping}{subsection.2.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces UK Scraping results}}{10}{table.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces The loss processes are coloured red, successfully captured full records in green, and the maximum possible yield in blue.}}{11}{figure.2.5}}
\newlabel{fig:UKSANK}{{2.5}{11}{The loss processes are coloured red, successfully captured full records in green, and the maximum possible yield in blue}{figure.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Very Large Scale Scraping}{11}{subsection.2.4.2}}
\newlabel{sec:CROSSREFSCRAPE}{{2.4.2}{11}{Very Large Scale Scraping}{subsection.2.4.2}{}}
\newlabel{sec:CROSSREFSCRAPE}{{2.4.2}{12}{Very Large Scale Scraping}{subsection.2.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Problems with ACS and Taylor and Francis}{12}{subsection.2.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces The request frequency is plotted in blue, the received pages frequency in red. The vertical dashed line shows where the server detected the scape and banned the IP.}}{13}{figure.2.6}}
\newlabel{fig:ACSBAN}{{2.6}{13}{The request frequency is plotted in blue, the received pages frequency in red. The vertical dashed line shows where the server detected the scape and banned the IP}{figure.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Analysis of Collected data}{13}{subsection.2.4.4}}
\newlabel{tab:LARGESCRAPERES}{{2.4.4}{14}{Analysis of Collected data}{subsection.2.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Large Scale Scraping Results}}{14}{table.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces The loss processes are coloured red, successfully captured full records in green, and the maximum possible yield in blue.}}{14}{figure.2.7}}
\newlabel{fig:LARGESANK}{{2.7}{14}{The loss processes are coloured red, successfully captured full records in green, and the maximum possible yield in blue}{figure.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Blue databases represent data with dois and metadata. Green databases represent meta-data, dois and abstracts. The purple database is the combined complete records, and the red database is the data deemed suitable for the training algorithm. database sizes and losses are annotated.}}{15}{figure.2.8}}
\newlabel{fig:DATABASES}{{2.8}{15}{Blue databases represent data with dois and metadata. Green databases represent meta-data, dois and abstracts. The purple database is the combined complete records, and the red database is the data deemed suitable for the training algorithm. database sizes and losses are annotated}{figure.2.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{Observations}{15}{section*.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Articles grouped by publisher in the Large Scale Scrape doi database. Only the top 12 publishers are shown.}}{16}{figure.2.9}}
\newlabel{fig:PUBPI}{{2.9}{16}{Articles grouped by publisher in the Large Scale Scrape doi database. Only the top 12 publishers are shown}{figure.2.9}{}}
\citation{zipf}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Articles grouped by publisher in the UK Doi database published by by each publisher. Only the top 12 publishers are shown.}}{17}{figure.2.10}}
\newlabel{fig:UKPUBPI}{{2.10}{17}{Articles grouped by publisher in the UK Doi database published by by each publisher. Only the top 12 publishers are shown}{figure.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces The log Frequency of words vs the log of their position in the rank in the word frequency table in blue. Best fit line in Red, gradient = -1.11, intercept 6.3. }}{17}{figure.2.11}}
\newlabel{fig:ZIPF}{{2.11}{17}{The log Frequency of words vs the log of their position in the rank in the word frequency table in blue. Best fit line in Red, gradient = -1.11, intercept 6.3}{figure.2.11}{}}
\newlabel{sec:SCRAPEANALYSIS}{{2.4.4}{17}{Observations}{table.2.3}{}}
\newlabel{tab:CORPUS STATS}{{2.4.4}{18}{Observations}{figure.2.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Titles and Abstracts in Training Database}}{18}{table.2.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Techniques for Language Processing}{19}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Background}{19}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Bag of Words}{19}{section.3.2}}
\newlabel{tab:BAGOFWORDS}{{3.2}{19}{Bag of Words}{section.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Bag of words}}{19}{table.3.1}}
\citation{WORD2VECKINGQUEEN}
\citation{olddistributed}
\citation{word2vec1}
\citation{word2vec2}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Bag of Citations}{20}{section.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Word2Vec}{20}{section.3.4}}
\citation{word2vec2}
\citation{word2veckingqueen}
\citation{word2vec2}
\citation{word2veckingqueen}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The training architectures of the Word2Vec training algorithm. Word vectors are denoted $v(i)$ for word i. In CBOW word i is predicted by the vector found by summing vectors surrounding i, and $v(i)$ is adjusted to be closer to this prediction. In skip-gram, word i's vector is pairwise compared to its context words, here i-1 and i+1 as a basis to improve $v(i)$.)}}{21}{figure.3.1}}
\newlabel{fig:CBOWSKIP}{{3.1}{21}{The training architectures of the Word2Vec training algorithm. Word vectors are denoted $v(i)$ for word i. In CBOW word i is predicted by the vector found by summing vectors surrounding i, and $v(i)$ is adjusted to be closer to this prediction. In skip-gram, word i's vector is pairwise compared to its context words, here i-1 and i+1 as a basis to improve $v(i)$.)}{figure.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Schematic Representation of how concepts can be represented in word vector space. Word2Vec is able to replicate this behaviour. The vector found by vec(‘King’)- vec(‘Man’)+vec(‘Woman’) is approximately equal to vec(‘Queen’). The model has been tested on thousands of similar examples\cite  {word2vec2}\cite  {word2veckingqueen}.}}{22}{figure.3.2}}
\newlabel{fig:KINGQUEEN}{{3.2}{22}{Schematic Representation of how concepts can be represented in word vector space. Word2Vec is able to replicate this behaviour. The vector found by vec(‘King’)- vec(‘Man’)+vec(‘Woman’) is approximately equal to vec(‘Queen’). The model has been tested on thousands of similar examples\cite {word2vec2}\cite {word2veckingqueen}}{figure.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Doc2Vec}{22}{section.3.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Algorithm Development}{23}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt:ALGORITHM}{{4}{23}{Algorithm Development}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Premise}{23}{section.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Data Sanitisation}{23}{section.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Word2Vec Models}{23}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Aggregation Techniques}{23}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Doc2Vec Models}{23}{section.4.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Validation of Algorithm}{24}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Visualisation Techniques}{24}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Simulated Inputs}{24}{section.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Word Similarities}{24}{section.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Document Similarities}{24}{section.5.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Analysis with Sample Dataset}{25}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions}{26}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibdata{References}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Recommendations for Further Work}{27}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{einstein}{{1}{1905}{{Einstein}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{28}{chapter*.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Appendix}{29}{chapter.9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}UK Departments scraped}{30}{section.9.1}}
